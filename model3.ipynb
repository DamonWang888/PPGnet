{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from scipy.io import loadmat\n",
    "import ipdb\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# session = InteractiveSession(config=config)\n",
    "class CnnLstm():\n",
    "    def __init__(self, classes, filters=32, kernel_size=40, pool_size=4, drop_rate=0.1, hidden_lstm=128):\n",
    "        \"\"\"\n",
    "        :param classes: 做多少分类任务\n",
    "        :param filters: 卷积长度\n",
    "        :param kernel_size: 卷积核的大小\n",
    "        :param pool_size: 池化层核的大小\n",
    "        :param drop_rate: drop out 的比例\n",
    "        :param hidden_lstm: lstm中的cell的个数\n",
    "        \"\"\"\n",
    "\n",
    "        self.classes = classes\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.drop_rate = drop_rate\n",
    "        self.hidden_lstm = hidden_lstm\n",
    "        self.model = self.build_model()\n",
    "#         print(self.model.summary())\n",
    "\n",
    "    def build_model(self):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, activation=keras.activations.relu))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.MaxPooling1D(pool_size=self.pool_size))\n",
    "        model.add(keras.layers.Dropout(rate=self.drop_rate))\n",
    "\n",
    "        model.add(keras.layers.Conv1D(filters=self.filters, kernel_size=self.kernel_size, activation=keras.activations.relu))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.MaxPooling1D(pool_size=self.pool_size))\n",
    "        model.add(keras.layers.Dropout(rate=self.drop_rate))\n",
    "\n",
    "        model.add(keras.layers.LSTM(self.hidden_lstm, activation=keras.activations.tanh, return_sequences=True))\n",
    "        model.add(keras.layers.LSTM(self.hidden_lstm, activation=keras.activations.tanh))\n",
    "\n",
    "        model.add(keras.layers.Dense(self.classes, activation=keras.activations.relu))\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(filepath):\n",
    "#     print(filepath)\n",
    "    time=loadmat(filepath)\n",
    "    time=time['ppg']\n",
    "    listslice=filepath.split('-')\n",
    "    label=listslice[2][:-4]\n",
    "    return time,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1622 data names\n",
      "datas shape:  (1622, 1000, 1)\n",
      "labels shape:  (1622, 1)\n"
     ]
    }
   ],
   "source": [
    "import glob,os\n",
    "def trainset(setdir):\n",
    "    datas=[]\n",
    "    labels=[]\n",
    "    filepaths=glob.glob(os.path.join(setdir, '*.mat')) \n",
    "    length=len(filepaths)\n",
    "    print('Found {} data names'.format(length))\n",
    "    for i in range(length):\n",
    "        time,label=LoadData(filepaths[i])\n",
    "        datas.append(time)\n",
    "        labels.append(label)\n",
    "    datas=np.asarray(datas)\n",
    "    labels=np.asarray(labels,dtype=float)\n",
    "    datas=datas.reshape((datas.shape[0],datas.shape[2],datas.shape[1]))\n",
    "    labels=labels.reshape((labels.shape[0],1))\n",
    "    print('datas shape: ',datas.shape)\n",
    "    print('labels shape: ',labels.shape)\n",
    "    return datas,labels\n",
    "datas,labels=trainset('/home/wcj/ReferenceProject/PPGnet/ppghr')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1622 samples\n",
      "Epoch 1/100\n",
      "1622/1622 [==============================] - 4s 2ms/sample - loss: 120.7793\n",
      "Epoch 2/100\n",
      "1622/1622 [==============================] - 1s 613us/sample - loss: 104.2165\n",
      "Epoch 3/100\n",
      "1622/1622 [==============================] - 1s 631us/sample - loss: 97.0596\n",
      "Epoch 4/100\n",
      "1622/1622 [==============================] - 1s 625us/sample - loss: 88.5966\n",
      "Epoch 5/100\n",
      "1622/1622 [==============================] - 1s 625us/sample - loss: 81.5057\n",
      "Epoch 6/100\n",
      "1622/1622 [==============================] - 1s 618us/sample - loss: 75.7539\n",
      "Epoch 7/100\n",
      "1622/1622 [==============================] - 1s 623us/sample - loss: 70.3273\n",
      "Epoch 8/100\n",
      "1622/1622 [==============================] - 1s 642us/sample - loss: 64.9179\n",
      "Epoch 9/100\n",
      "1622/1622 [==============================] - 1s 642us/sample - loss: 59.8604\n",
      "Epoch 10/100\n",
      "1622/1622 [==============================] - 1s 630us/sample - loss: 54.8807\n",
      "Epoch 11/100\n",
      "1622/1622 [==============================] - 1s 619us/sample - loss: 50.4816\n",
      "Epoch 12/100\n",
      "1622/1622 [==============================] - 1s 625us/sample - loss: 46.2986\n",
      "Epoch 13/100\n",
      "1622/1622 [==============================] - 1s 617us/sample - loss: 42.1626\n",
      "Epoch 14/100\n",
      "1622/1622 [==============================] - 1s 621us/sample - loss: 38.2103\n",
      "Epoch 15/100\n",
      "1622/1622 [==============================] - 1s 628us/sample - loss: 34.4847\n",
      "Epoch 16/100\n",
      "1622/1622 [==============================] - 1s 630us/sample - loss: 31.1569\n",
      "Epoch 17/100\n",
      "1622/1622 [==============================] - 1s 622us/sample - loss: 28.1635\n",
      "Epoch 18/100\n",
      "1622/1622 [==============================] - 1s 624us/sample - loss: 25.6198\n",
      "Epoch 19/100\n",
      "1622/1622 [==============================] - 1s 639us/sample - loss: 23.6736\n",
      "Epoch 20/100\n",
      "1622/1622 [==============================] - 1s 629us/sample - loss: 22.1329\n",
      "Epoch 21/100\n",
      "1622/1622 [==============================] - 1s 638us/sample - loss: 20.8868\n",
      "Epoch 22/100\n",
      "1622/1622 [==============================] - 1s 664us/sample - loss: 19.9578\n",
      "Epoch 23/100\n",
      "1622/1622 [==============================] - 1s 647us/sample - loss: 19.4357\n",
      "Epoch 24/100\n",
      "1622/1622 [==============================] - 1s 651us/sample - loss: 19.1945\n",
      "Epoch 25/100\n",
      " 600/1622 [==========>...................] - ETA: 0s - loss: 19.1991"
     ]
    }
   ],
   "source": [
    "EPOCHS=100\n",
    "BATCH_SIZE=300\n",
    "# datas=tf.data.Dataset.from_tensor_slices(datas)\n",
    "\n",
    "# datas=np.random.randn(100,1000,1)\n",
    "# # train_y=np.random.random_integers(2,size=(100,1))\n",
    "# labels=np.random.randint(1,size=(100,1))\n",
    "# print('datas shape: ',datas.shape)\n",
    "# print('labels shape: ',labels.shape)\n",
    "# print(labels[0])\n",
    "# print(datas[0])\n",
    "cnnlstm = CnnLstm(classes=1,hidden_lstm=1000)\n",
    "cnnlstm.model.compile(optimizer='RMSprop',    # 这里是优化器的选择\n",
    "                          loss='mean_absolute_error'  # 损失函数的选择\n",
    "                                )                              # 训练\n",
    "# cnnlstm.model.summary()\n",
    "cnnlstm.model.fit(datas, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1622 samples\n",
      "Epoch 1/100\n",
      "1622/1622 [==============================] - 1s 652us/sample - loss: 8.1870\n",
      "Epoch 2/100\n",
      "1622/1622 [==============================] - 1s 631us/sample - loss: 8.8758\n",
      "Epoch 3/100\n",
      "1622/1622 [==============================] - 1s 634us/sample - loss: 8.4764\n",
      "Epoch 4/100\n",
      "1622/1622 [==============================] - 1s 645us/sample - loss: 7.6474\n",
      "Epoch 5/100\n",
      "1622/1622 [==============================] - 1s 644us/sample - loss: 9.0493\n",
      "Epoch 6/100\n",
      "1622/1622 [==============================] - 1s 642us/sample - loss: 8.2454\n",
      "Epoch 7/100\n",
      "1622/1622 [==============================] - 1s 645us/sample - loss: 7.8403\n",
      "Epoch 8/100\n",
      "1622/1622 [==============================] - 1s 655us/sample - loss: 7.0589\n",
      "Epoch 9/100\n",
      "1622/1622 [==============================] - 1s 664us/sample - loss: 7.1819\n",
      "Epoch 10/100\n",
      "1622/1622 [==============================] - 1s 662us/sample - loss: 7.8999\n",
      "Epoch 11/100\n",
      "1622/1622 [==============================] - 1s 660us/sample - loss: 7.8895\n",
      "Epoch 12/100\n",
      "1622/1622 [==============================] - 1s 665us/sample - loss: 6.6969\n",
      "Epoch 13/100\n",
      "1622/1622 [==============================] - 1s 666us/sample - loss: 7.1141\n",
      "Epoch 14/100\n",
      "1622/1622 [==============================] - 1s 664us/sample - loss: 7.4077\n",
      "Epoch 15/100\n",
      "1622/1622 [==============================] - 1s 665us/sample - loss: 6.8533\n",
      "Epoch 16/100\n",
      "1622/1622 [==============================] - 1s 672us/sample - loss: 6.9195\n",
      "Epoch 17/100\n",
      "1622/1622 [==============================] - 1s 669us/sample - loss: 7.3084\n",
      "Epoch 18/100\n",
      "1622/1622 [==============================] - 1s 676us/sample - loss: 6.3924\n",
      "Epoch 19/100\n",
      "1622/1622 [==============================] - 1s 677us/sample - loss: 6.2794\n",
      "Epoch 20/100\n",
      "1622/1622 [==============================] - 1s 678us/sample - loss: 6.6536\n",
      "Epoch 21/100\n",
      "1622/1622 [==============================] - 1s 689us/sample - loss: 8.1368\n",
      "Epoch 22/100\n",
      "1622/1622 [==============================] - 1s 691us/sample - loss: 6.9767\n",
      "Epoch 23/100\n",
      "1622/1622 [==============================] - 1s 698us/sample - loss: 5.2973\n",
      "Epoch 24/100\n",
      "1622/1622 [==============================] - 1s 696us/sample - loss: 5.9897\n",
      "Epoch 25/100\n",
      "1622/1622 [==============================] - 1s 694us/sample - loss: 5.9458\n",
      "Epoch 26/100\n",
      "1622/1622 [==============================] - 1s 697us/sample - loss: 6.2796\n",
      "Epoch 27/100\n",
      "1622/1622 [==============================] - 1s 699us/sample - loss: 6.1642\n",
      "Epoch 28/100\n",
      "1622/1622 [==============================] - 1s 685us/sample - loss: 5.7009\n",
      "Epoch 29/100\n",
      "1622/1622 [==============================] - 1s 693us/sample - loss: 5.0787\n",
      "Epoch 30/100\n",
      "1622/1622 [==============================] - 1s 693us/sample - loss: 5.3809\n",
      "Epoch 31/100\n",
      "1622/1622 [==============================] - 1s 695us/sample - loss: 6.5716\n",
      "Epoch 32/100\n",
      "1622/1622 [==============================] - 1s 693us/sample - loss: 4.4840\n",
      "Epoch 33/100\n",
      "1622/1622 [==============================] - 1s 703us/sample - loss: 5.9277\n",
      "Epoch 34/100\n",
      "1622/1622 [==============================] - 1s 692us/sample - loss: 4.8346\n",
      "Epoch 35/100\n",
      "1622/1622 [==============================] - 1s 702us/sample - loss: 4.6262\n",
      "Epoch 36/100\n",
      "1622/1622 [==============================] - 1s 694us/sample - loss: 4.4474\n",
      "Epoch 37/100\n",
      "1622/1622 [==============================] - 1s 695us/sample - loss: 4.4239\n",
      "Epoch 38/100\n",
      "1622/1622 [==============================] - 1s 697us/sample - loss: 4.5189\n",
      "Epoch 39/100\n",
      "1622/1622 [==============================] - 1s 695us/sample - loss: 7.0770\n",
      "Epoch 40/100\n",
      "1622/1622 [==============================] - 1s 693us/sample - loss: 6.9814\n",
      "Epoch 41/100\n",
      "1622/1622 [==============================] - 1s 696us/sample - loss: 3.9736\n",
      "Epoch 42/100\n",
      "1622/1622 [==============================] - 1s 694us/sample - loss: 4.9496\n",
      "Epoch 43/100\n",
      "1622/1622 [==============================] - 1s 720us/sample - loss: 3.6437\n",
      "Epoch 44/100\n",
      "1622/1622 [==============================] - 1s 753us/sample - loss: 3.8911\n",
      "Epoch 45/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 3.3877\n",
      "Epoch 46/100\n",
      "1622/1622 [==============================] - 1s 725us/sample - loss: 4.3531\n",
      "Epoch 47/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 3.2124\n",
      "Epoch 48/100\n",
      "1622/1622 [==============================] - 1s 731us/sample - loss: 4.3228\n",
      "Epoch 49/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 4.1506\n",
      "Epoch 50/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 3.4011\n",
      "Epoch 51/100\n",
      "1622/1622 [==============================] - 1s 720us/sample - loss: 4.9522\n",
      "Epoch 52/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 3.5702\n",
      "Epoch 53/100\n",
      "1622/1622 [==============================] - 1s 738us/sample - loss: 3.6408\n",
      "Epoch 54/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 3.3974\n",
      "Epoch 55/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 3.3532\n",
      "Epoch 56/100\n",
      "1622/1622 [==============================] - 1s 738us/sample - loss: 3.0512\n",
      "Epoch 57/100\n",
      "1622/1622 [==============================] - 1s 722us/sample - loss: 2.8950\n",
      "Epoch 58/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 3.3796\n",
      "Epoch 59/100\n",
      "1622/1622 [==============================] - 1s 730us/sample - loss: 2.3973\n",
      "Epoch 60/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 3.2279\n",
      "Epoch 61/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 3.2944\n",
      "Epoch 62/100\n",
      "1622/1622 [==============================] - 1s 720us/sample - loss: 3.0114\n",
      "Epoch 63/100\n",
      "1622/1622 [==============================] - 1s 725us/sample - loss: 2.6999\n",
      "Epoch 64/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 2.6511\n",
      "Epoch 65/100\n",
      "1622/1622 [==============================] - 1s 730us/sample - loss: 3.9921\n",
      "Epoch 66/100\n",
      "1622/1622 [==============================] - 1s 743us/sample - loss: 3.2396\n",
      "Epoch 67/100\n",
      "1622/1622 [==============================] - 1s 727us/sample - loss: 3.4513\n",
      "Epoch 68/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 2.6043\n",
      "Epoch 69/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 2.2604\n",
      "Epoch 70/100\n",
      "1622/1622 [==============================] - 1s 722us/sample - loss: 3.4793\n",
      "Epoch 71/100\n",
      "1622/1622 [==============================] - 1s 722us/sample - loss: 2.5730\n",
      "Epoch 72/100\n",
      "1622/1622 [==============================] - 1s 716us/sample - loss: 2.7697\n",
      "Epoch 73/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 2.5871\n",
      "Epoch 74/100\n",
      "1622/1622 [==============================] - 1s 730us/sample - loss: 2.6166\n",
      "Epoch 75/100\n",
      "1622/1622 [==============================] - 1s 708us/sample - loss: 3.0014\n",
      "Epoch 76/100\n",
      "1622/1622 [==============================] - 1s 748us/sample - loss: 3.4622\n",
      "Epoch 77/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 2.7044\n",
      "Epoch 78/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 2.5806\n",
      "Epoch 79/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 2.6550\n",
      "Epoch 80/100\n",
      "1622/1622 [==============================] - 1s 704us/sample - loss: 2.8045\n",
      "Epoch 81/100\n",
      "1622/1622 [==============================] - 1s 750us/sample - loss: 2.8221\n",
      "Epoch 82/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 3.4487\n",
      "Epoch 83/100\n",
      "1622/1622 [==============================] - 1s 717us/sample - loss: 2.6031\n",
      "Epoch 84/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 2.3927\n",
      "Epoch 85/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 2.1191\n",
      "Epoch 86/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 2.2185\n",
      "Epoch 87/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 2.4853\n",
      "Epoch 88/100\n",
      "1622/1622 [==============================] - 1s 725us/sample - loss: 2.4665\n",
      "Epoch 89/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 2.4174\n",
      "Epoch 90/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 2.3767\n",
      "Epoch 91/100\n",
      "1622/1622 [==============================] - 1s 724us/sample - loss: 2.0732\n",
      "Epoch 92/100\n",
      "1622/1622 [==============================] - 1s 723us/sample - loss: 2.8307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "1622/1622 [==============================] - 1s 720us/sample - loss: 1.9952\n",
      "Epoch 94/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 2.0967\n",
      "Epoch 95/100\n",
      "1622/1622 [==============================] - 1s 714us/sample - loss: 2.2075\n",
      "Epoch 96/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 2.2916\n",
      "Epoch 97/100\n",
      "1622/1622 [==============================] - 1s 707us/sample - loss: 2.3077\n",
      "Epoch 98/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 2.0494\n",
      "Epoch 99/100\n",
      "1622/1622 [==============================] - 1s 723us/sample - loss: 1.8211\n",
      "Epoch 100/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 1.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fcf762350>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnlstm.model.fit(datas, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1622 samples\n",
      "Epoch 1/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 2.2186\n",
      "Epoch 2/100\n",
      "1622/1622 [==============================] - 1s 705us/sample - loss: 2.0508\n",
      "Epoch 3/100\n",
      "1622/1622 [==============================] - 1s 707us/sample - loss: 1.8120\n",
      "Epoch 4/100\n",
      "1622/1622 [==============================] - 1s 663us/sample - loss: 2.6043\n",
      "Epoch 5/100\n",
      "1622/1622 [==============================] - 1s 688us/sample - loss: 1.8648\n",
      "Epoch 6/100\n",
      "1622/1622 [==============================] - 1s 664us/sample - loss: 2.0059\n",
      "Epoch 7/100\n",
      "1622/1622 [==============================] - 1s 620us/sample - loss: 1.9857\n",
      "Epoch 8/100\n",
      "1622/1622 [==============================] - 1s 625us/sample - loss: 1.5347\n",
      "Epoch 9/100\n",
      "1622/1622 [==============================] - 1s 626us/sample - loss: 1.8658\n",
      "Epoch 10/100\n",
      "1622/1622 [==============================] - 1s 635us/sample - loss: 2.4675\n",
      "Epoch 11/100\n",
      "1622/1622 [==============================] - 1s 662us/sample - loss: 2.0924\n",
      "Epoch 12/100\n",
      "1622/1622 [==============================] - 1s 677us/sample - loss: 1.7231\n",
      "Epoch 13/100\n",
      "1622/1622 [==============================] - 1s 678us/sample - loss: 8.2508\n",
      "Epoch 14/100\n",
      "1622/1622 [==============================] - 1s 677us/sample - loss: 2.1428\n",
      "Epoch 15/100\n",
      "1622/1622 [==============================] - 1s 689us/sample - loss: 1.7753\n",
      "Epoch 16/100\n",
      "1622/1622 [==============================] - 1s 672us/sample - loss: 1.9259\n",
      "Epoch 17/100\n",
      "1622/1622 [==============================] - 1s 700us/sample - loss: 1.8333\n",
      "Epoch 18/100\n",
      "1622/1622 [==============================] - 1s 770us/sample - loss: 1.9242\n",
      "Epoch 19/100\n",
      "1622/1622 [==============================] - 1s 721us/sample - loss: 1.6923\n",
      "Epoch 20/100\n",
      "1622/1622 [==============================] - 1s 708us/sample - loss: 1.7629\n",
      "Epoch 21/100\n",
      "1622/1622 [==============================] - 1s 712us/sample - loss: 2.2904\n",
      "Epoch 22/100\n",
      "1622/1622 [==============================] - 1s 697us/sample - loss: 1.9238\n",
      "Epoch 23/100\n",
      "1622/1622 [==============================] - 1s 697us/sample - loss: 1.9580\n",
      "Epoch 24/100\n",
      "1622/1622 [==============================] - 1s 724us/sample - loss: 1.8170\n",
      "Epoch 25/100\n",
      "1622/1622 [==============================] - 1s 714us/sample - loss: 1.7461\n",
      "Epoch 26/100\n",
      "1622/1622 [==============================] - 1s 692us/sample - loss: 1.8336\n",
      "Epoch 27/100\n",
      "1622/1622 [==============================] - 1s 702us/sample - loss: 1.6069\n",
      "Epoch 28/100\n",
      "1622/1622 [==============================] - 1s 702us/sample - loss: 1.7899\n",
      "Epoch 29/100\n",
      "1622/1622 [==============================] - 1s 710us/sample - loss: 1.6066\n",
      "Epoch 30/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 1.8659\n",
      "Epoch 31/100\n",
      "1622/1622 [==============================] - 1s 753us/sample - loss: 1.6508\n",
      "Epoch 32/100\n",
      "1622/1622 [==============================] - 1s 724us/sample - loss: 1.4878\n",
      "Epoch 33/100\n",
      "1622/1622 [==============================] - 1s 707us/sample - loss: 3.0119\n",
      "Epoch 34/100\n",
      "1622/1622 [==============================] - 1s 717us/sample - loss: 1.9290\n",
      "Epoch 35/100\n",
      "1622/1622 [==============================] - 1s 773us/sample - loss: 1.5960\n",
      "Epoch 36/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 1.6409\n",
      "Epoch 37/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 1.2257\n",
      "Epoch 38/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 1.5984\n",
      "Epoch 39/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 1.5133\n",
      "Epoch 40/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 1.5665\n",
      "Epoch 41/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 1.5617\n",
      "Epoch 42/100\n",
      "1622/1622 [==============================] - 1s 756us/sample - loss: 1.4141\n",
      "Epoch 43/100\n",
      "1622/1622 [==============================] - 1s 716us/sample - loss: 1.4000\n",
      "Epoch 44/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 1.5276\n",
      "Epoch 45/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 1.3638\n",
      "Epoch 46/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 1.6858\n",
      "Epoch 47/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 1.3044\n",
      "Epoch 48/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 1.9785\n",
      "Epoch 49/100\n",
      "1622/1622 [==============================] - 1s 749us/sample - loss: 1.5014\n",
      "Epoch 50/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 1.6466\n",
      "Epoch 51/100\n",
      "1622/1622 [==============================] - 1s 772us/sample - loss: 1.2521\n",
      "Epoch 52/100\n",
      "1622/1622 [==============================] - 1s 727us/sample - loss: 1.4931\n",
      "Epoch 53/100\n",
      "1622/1622 [==============================] - 1s 769us/sample - loss: 1.3281\n",
      "Epoch 54/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 1.5389\n",
      "Epoch 55/100\n",
      "1622/1622 [==============================] - 1s 740us/sample - loss: 1.5206\n",
      "Epoch 56/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 1.6002\n",
      "Epoch 57/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 1.4750\n",
      "Epoch 58/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 1.3056\n",
      "Epoch 59/100\n",
      "1622/1622 [==============================] - 1s 752us/sample - loss: 1.5652\n",
      "Epoch 60/100\n",
      "1622/1622 [==============================] - 1s 765us/sample - loss: 1.7992\n",
      "Epoch 61/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 1.5986\n",
      "Epoch 62/100\n",
      "1622/1622 [==============================] - 1s 724us/sample - loss: 1.4938\n",
      "Epoch 63/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 1.7453\n",
      "Epoch 64/100\n",
      "1622/1622 [==============================] - 1s 769us/sample - loss: 1.2550\n",
      "Epoch 65/100\n",
      "1622/1622 [==============================] - 1s 759us/sample - loss: 1.2527\n",
      "Epoch 66/100\n",
      "1622/1622 [==============================] - 1s 759us/sample - loss: 1.6390\n",
      "Epoch 67/100\n",
      "1622/1622 [==============================] - 1s 751us/sample - loss: 1.3784\n",
      "Epoch 68/100\n",
      "1622/1622 [==============================] - 1s 754us/sample - loss: 1.4388\n",
      "Epoch 69/100\n",
      "1622/1622 [==============================] - 1s 809us/sample - loss: 1.4645\n",
      "Epoch 70/100\n",
      "1622/1622 [==============================] - 1s 754us/sample - loss: 1.5093\n",
      "Epoch 71/100\n",
      "1622/1622 [==============================] - 1s 743us/sample - loss: 1.3369\n",
      "Epoch 72/100\n",
      "1622/1622 [==============================] - 1s 723us/sample - loss: 1.5247\n",
      "Epoch 73/100\n",
      "1622/1622 [==============================] - 1s 751us/sample - loss: 1.1335\n",
      "Epoch 74/100\n",
      "1622/1622 [==============================] - 1s 784us/sample - loss: 1.6345\n",
      "Epoch 75/100\n",
      "1622/1622 [==============================] - 1s 755us/sample - loss: 1.3341\n",
      "Epoch 76/100\n",
      "1622/1622 [==============================] - 1s 738us/sample - loss: 1.5893\n",
      "Epoch 77/100\n",
      "1622/1622 [==============================] - 1s 733us/sample - loss: 1.4749\n",
      "Epoch 78/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 1.2427\n",
      "Epoch 79/100\n",
      "1622/1622 [==============================] - 1s 740us/sample - loss: 1.5783\n",
      "Epoch 80/100\n",
      "1622/1622 [==============================] - 1s 780us/sample - loss: 1.0030\n",
      "Epoch 81/100\n",
      "1622/1622 [==============================] - 1s 777us/sample - loss: 1.5287\n",
      "Epoch 82/100\n",
      "1622/1622 [==============================] - 1s 750us/sample - loss: 1.2844\n",
      "Epoch 83/100\n",
      "1622/1622 [==============================] - 1s 724us/sample - loss: 1.2010\n",
      "Epoch 84/100\n",
      "1622/1622 [==============================] - 1s 753us/sample - loss: 1.3836\n",
      "Epoch 85/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 1.3263\n",
      "Epoch 86/100\n",
      "1622/1622 [==============================] - 1s 796us/sample - loss: 1.2214\n",
      "Epoch 87/100\n",
      "1622/1622 [==============================] - 1s 747us/sample - loss: 1.3750\n",
      "Epoch 88/100\n",
      "1622/1622 [==============================] - 1s 740us/sample - loss: 1.0485\n",
      "Epoch 89/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 1.4398\n",
      "Epoch 90/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 1.2121\n",
      "Epoch 91/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 1.3067\n",
      "Epoch 92/100\n",
      "1622/1622 [==============================] - 1s 765us/sample - loss: 1.0793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 1.3570\n",
      "Epoch 94/100\n",
      "1622/1622 [==============================] - 1s 748us/sample - loss: 1.3289\n",
      "Epoch 95/100\n",
      "1622/1622 [==============================] - 1s 731us/sample - loss: 1.3660\n",
      "Epoch 96/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 1.3355\n",
      "Epoch 97/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 1.2509\n",
      "Epoch 98/100\n",
      "1622/1622 [==============================] - 1s 787us/sample - loss: 1.0295\n",
      "Epoch 99/100\n",
      "1622/1622 [==============================] - 1s 771us/sample - loss: 1.3330\n",
      "Epoch 100/100\n",
      "1622/1622 [==============================] - 1s 756us/sample - loss: 1.2873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fecf8b690>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnlstm.model.fit(datas, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1622 samples\n",
      "Epoch 1/100\n",
      "1622/1622 [==============================] - 4s 3ms/sample - loss: 0.8346\n",
      "Epoch 2/100\n",
      "1622/1622 [==============================] - 1s 650us/sample - loss: 0.6896\n",
      "Epoch 3/100\n",
      "1622/1622 [==============================] - 1s 660us/sample - loss: 0.6334\n",
      "Epoch 4/100\n",
      "1622/1622 [==============================] - 1s 657us/sample - loss: 0.5898\n",
      "Epoch 5/100\n",
      "1622/1622 [==============================] - 1s 690us/sample - loss: 0.6083\n",
      "Epoch 6/100\n",
      "1622/1622 [==============================] - 1s 698us/sample - loss: 0.5874\n",
      "Epoch 7/100\n",
      "1622/1622 [==============================] - 1s 698us/sample - loss: 0.5570\n",
      "Epoch 8/100\n",
      "1622/1622 [==============================] - 1s 657us/sample - loss: 0.5685\n",
      "Epoch 9/100\n",
      "1622/1622 [==============================] - 1s 703us/sample - loss: 0.5404\n",
      "Epoch 10/100\n",
      "1622/1622 [==============================] - 1s 675us/sample - loss: 0.5256\n",
      "Epoch 11/100\n",
      "1622/1622 [==============================] - 1s 672us/sample - loss: 0.5365\n",
      "Epoch 12/100\n",
      "1622/1622 [==============================] - 1s 697us/sample - loss: 0.5281\n",
      "Epoch 13/100\n",
      "1622/1622 [==============================] - 1s 730us/sample - loss: 0.4938\n",
      "Epoch 14/100\n",
      "1622/1622 [==============================] - 1s 673us/sample - loss: 0.5007\n",
      "Epoch 15/100\n",
      "1622/1622 [==============================] - 1s 695us/sample - loss: 0.5110\n",
      "Epoch 16/100\n",
      "1622/1622 [==============================] - 1s 706us/sample - loss: 0.4753\n",
      "Epoch 17/100\n",
      "1622/1622 [==============================] - 1s 699us/sample - loss: 0.4849\n",
      "Epoch 18/100\n",
      "1622/1622 [==============================] - 1s 713us/sample - loss: 0.4570\n",
      "Epoch 19/100\n",
      "1622/1622 [==============================] - 1s 747us/sample - loss: 0.4715\n",
      "Epoch 20/100\n",
      "1622/1622 [==============================] - 1s 766us/sample - loss: 0.4475\n",
      "Epoch 21/100\n",
      "1622/1622 [==============================] - 1s 694us/sample - loss: 0.4531\n",
      "Epoch 22/100\n",
      "1622/1622 [==============================] - 1s 662us/sample - loss: 0.4507\n",
      "Epoch 23/100\n",
      "1622/1622 [==============================] - 1s 666us/sample - loss: 0.4572\n",
      "Epoch 24/100\n",
      "1622/1622 [==============================] - 1s 688us/sample - loss: 0.4444\n",
      "Epoch 25/100\n",
      "1622/1622 [==============================] - 1s 683us/sample - loss: 0.4603\n",
      "Epoch 26/100\n",
      "1622/1622 [==============================] - 1s 754us/sample - loss: 0.4394\n",
      "Epoch 27/100\n",
      "1622/1622 [==============================] - 1s 757us/sample - loss: 0.4327\n",
      "Epoch 28/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 0.4464\n",
      "Epoch 29/100\n",
      "1622/1622 [==============================] - 1s 730us/sample - loss: 0.4079\n",
      "Epoch 30/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 0.4158\n",
      "Epoch 31/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 0.3964\n",
      "Epoch 32/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 0.4317\n",
      "Epoch 33/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 0.4112\n",
      "Epoch 34/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 0.4372\n",
      "Epoch 35/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 0.3999\n",
      "Epoch 36/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 0.3964\n",
      "Epoch 37/100\n",
      "1622/1622 [==============================] - 1s 690us/sample - loss: 0.4086\n",
      "Epoch 38/100\n",
      "1622/1622 [==============================] - 1s 710us/sample - loss: 0.3877\n",
      "Epoch 39/100\n",
      "1622/1622 [==============================] - 1s 681us/sample - loss: 0.4136\n",
      "Epoch 40/100\n",
      "1622/1622 [==============================] - 1s 688us/sample - loss: 0.4342\n",
      "Epoch 41/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 0.3987\n",
      "Epoch 42/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 0.3822\n",
      "Epoch 43/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 0.3976\n",
      "Epoch 44/100\n",
      "1622/1622 [==============================] - 1s 711us/sample - loss: 0.3909\n",
      "Epoch 45/100\n",
      "1622/1622 [==============================] - 1s 711us/sample - loss: 0.3904\n",
      "Epoch 46/100\n",
      "1622/1622 [==============================] - 1s 717us/sample - loss: 0.3679\n",
      "Epoch 47/100\n",
      "1622/1622 [==============================] - 1s 711us/sample - loss: 0.3636\n",
      "Epoch 48/100\n",
      "1622/1622 [==============================] - 1s 692us/sample - loss: 0.4028\n",
      "Epoch 49/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 0.3824\n",
      "Epoch 50/100\n",
      "1622/1622 [==============================] - 1s 785us/sample - loss: 0.3633\n",
      "Epoch 51/100\n",
      "1622/1622 [==============================] - 1s 731us/sample - loss: 0.3981\n",
      "Epoch 52/100\n",
      "1622/1622 [==============================] - 1s 708us/sample - loss: 0.3584\n",
      "Epoch 53/100\n",
      "1622/1622 [==============================] - 1s 698us/sample - loss: 0.3720\n",
      "Epoch 54/100\n",
      "1622/1622 [==============================] - 1s 759us/sample - loss: 0.3493\n",
      "Epoch 55/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 0.3793\n",
      "Epoch 56/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.3676\n",
      "Epoch 57/100\n",
      "1622/1622 [==============================] - 1s 737us/sample - loss: 0.3706\n",
      "Epoch 58/100\n",
      "1622/1622 [==============================] - 1s 710us/sample - loss: 0.3987\n",
      "Epoch 59/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 0.3804\n",
      "Epoch 60/100\n",
      "1622/1622 [==============================] - 1s 720us/sample - loss: 0.3569\n",
      "Epoch 61/100\n",
      "1622/1622 [==============================] - 1s 714us/sample - loss: 0.3617\n",
      "Epoch 62/100\n",
      "1622/1622 [==============================] - 1s 709us/sample - loss: 0.3695\n",
      "Epoch 63/100\n",
      "1622/1622 [==============================] - 1s 733us/sample - loss: 0.3664\n",
      "Epoch 64/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 0.3576\n",
      "Epoch 65/100\n",
      "1622/1622 [==============================] - 1s 722us/sample - loss: 0.3601\n",
      "Epoch 66/100\n",
      "1622/1622 [==============================] - 1s 721us/sample - loss: 0.3590\n",
      "Epoch 67/100\n",
      "1622/1622 [==============================] - 1s 716us/sample - loss: 0.3599\n",
      "Epoch 68/100\n",
      "1622/1622 [==============================] - 1s 707us/sample - loss: 0.3274\n",
      "Epoch 69/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 0.3594\n",
      "Epoch 70/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 0.3603\n",
      "Epoch 71/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.3806\n",
      "Epoch 72/100\n",
      "1622/1622 [==============================] - 1s 752us/sample - loss: 0.3531\n",
      "Epoch 73/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.3322\n",
      "Epoch 74/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 0.3457\n",
      "Epoch 75/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.3374\n",
      "Epoch 76/100\n",
      "1622/1622 [==============================] - 1s 714us/sample - loss: 0.3454\n",
      "Epoch 77/100\n",
      "1622/1622 [==============================] - 1s 709us/sample - loss: 0.3402\n",
      "Epoch 78/100\n",
      "1622/1622 [==============================] - 1s 777us/sample - loss: 0.3290\n",
      "Epoch 79/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 0.3284\n",
      "Epoch 80/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 0.3311\n",
      "Epoch 81/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 0.3236\n",
      "Epoch 82/100\n",
      "1622/1622 [==============================] - 1s 747us/sample - loss: 0.3387\n",
      "Epoch 83/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 0.3162\n",
      "Epoch 84/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 0.3455\n",
      "Epoch 85/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 0.3423\n",
      "Epoch 86/100\n",
      "1622/1622 [==============================] - 1s 768us/sample - loss: 0.3339\n",
      "Epoch 87/100\n",
      "1622/1622 [==============================] - 1s 802us/sample - loss: 0.3226\n",
      "Epoch 88/100\n",
      "1622/1622 [==============================] - 1s 725us/sample - loss: 0.3298\n",
      "Epoch 89/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 0.3313\n",
      "Epoch 90/100\n",
      "1622/1622 [==============================] - 1s 726us/sample - loss: 0.3281\n",
      "Epoch 91/100\n",
      "1622/1622 [==============================] - 1s 727us/sample - loss: 0.3354\n",
      "Epoch 92/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 0.3085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100\n",
      "1622/1622 [==============================] - 1s 762us/sample - loss: 0.3488\n",
      "Epoch 94/100\n",
      "1622/1622 [==============================] - 1s 766us/sample - loss: 0.3317\n",
      "Epoch 95/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.3247\n",
      "Epoch 96/100\n",
      "1622/1622 [==============================] - 1s 738us/sample - loss: 0.3109\n",
      "Epoch 97/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.3032\n",
      "Epoch 98/100\n",
      "1622/1622 [==============================] - 1s 736us/sample - loss: 0.3144\n",
      "Epoch 99/100\n",
      "1622/1622 [==============================] - 1s 766us/sample - loss: 0.3148\n",
      "Epoch 100/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.3083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fcf682250>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt=keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "cnnlstm.model.compile(optimizer=opt,    # 这里是优化器的选择\n",
    "                          loss='mean_absolute_error'  # 损失函数的选择\n",
    "                                )                              # 训练\n",
    "# cnnlstm.model.summary()\n",
    "cnnlstm.model.fit(datas, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1622 samples\n",
      "Epoch 1/100\n",
      "1622/1622 [==============================] - 5s 3ms/sample - loss: 0.3078\n",
      "Epoch 2/100\n",
      "1622/1622 [==============================] - 1s 674us/sample - loss: 0.3016\n",
      "Epoch 3/100\n",
      "1622/1622 [==============================] - 1s 673us/sample - loss: 0.3014\n",
      "Epoch 4/100\n",
      "1622/1622 [==============================] - 1s 677us/sample - loss: 0.3039\n",
      "Epoch 5/100\n",
      "1622/1622 [==============================] - 1s 707us/sample - loss: 0.2865\n",
      "Epoch 6/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 0.2756\n",
      "Epoch 7/100\n",
      "1622/1622 [==============================] - 1s 696us/sample - loss: 0.3014s - loss: 0.301\n",
      "Epoch 8/100\n",
      "1622/1622 [==============================] - 1s 695us/sample - loss: 0.2930\n",
      "Epoch 9/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 0.2825\n",
      "Epoch 10/100\n",
      "1622/1622 [==============================] - 1s 693us/sample - loss: 0.2895\n",
      "Epoch 11/100\n",
      "1622/1622 [==============================] - 1s 678us/sample - loss: 0.2825\n",
      "Epoch 12/100\n",
      "1622/1622 [==============================] - 1s 734us/sample - loss: 0.2840\n",
      "Epoch 13/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 0.2748\n",
      "Epoch 14/100\n",
      "1622/1622 [==============================] - 1s 692us/sample - loss: 0.2792\n",
      "Epoch 15/100\n",
      "1622/1622 [==============================] - 1s 719us/sample - loss: 0.2874\n",
      "Epoch 16/100\n",
      "1622/1622 [==============================] - 1s 722us/sample - loss: 0.2798\n",
      "Epoch 17/100\n",
      "1622/1622 [==============================] - 1s 688us/sample - loss: 0.2945\n",
      "Epoch 18/100\n",
      "1622/1622 [==============================] - 1s 703us/sample - loss: 0.2968\n",
      "Epoch 19/100\n",
      "1622/1622 [==============================] - 1s 706us/sample - loss: 0.2746\n",
      "Epoch 20/100\n",
      "1622/1622 [==============================] - 1s 731us/sample - loss: 0.2820\n",
      "Epoch 21/100\n",
      "1622/1622 [==============================] - 1s 711us/sample - loss: 0.2874\n",
      "Epoch 22/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.2857\n",
      "Epoch 23/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 0.2787\n",
      "Epoch 24/100\n",
      "1622/1622 [==============================] - 1s 718us/sample - loss: 0.2655\n",
      "Epoch 25/100\n",
      "1622/1622 [==============================] - 1s 721us/sample - loss: 0.2706\n",
      "Epoch 26/100\n",
      "1622/1622 [==============================] - 1s 758us/sample - loss: 0.3066\n",
      "Epoch 27/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 0.2829\n",
      "Epoch 28/100\n",
      "1622/1622 [==============================] - 1s 715us/sample - loss: 0.2673\n",
      "Epoch 29/100\n",
      "1622/1622 [==============================] - 1s 696us/sample - loss: 0.2904\n",
      "Epoch 30/100\n",
      "1622/1622 [==============================] - 1s 752us/sample - loss: 0.2753\n",
      "Epoch 31/100\n",
      "1622/1622 [==============================] - 1s 735us/sample - loss: 0.2924\n",
      "Epoch 32/100\n",
      "1622/1622 [==============================] - 1s 716us/sample - loss: 0.2773\n",
      "Epoch 33/100\n",
      "1622/1622 [==============================] - 1s 712us/sample - loss: 0.2902\n",
      "Epoch 34/100\n",
      "1622/1622 [==============================] - 1s 752us/sample - loss: 0.2842\n",
      "Epoch 35/100\n",
      "1622/1622 [==============================] - 1s 769us/sample - loss: 0.2828\n",
      "Epoch 36/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 0.2678\n",
      "Epoch 37/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.2879\n",
      "Epoch 38/100\n",
      "1622/1622 [==============================] - 1s 763us/sample - loss: 0.2818\n",
      "Epoch 39/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 0.2914\n",
      "Epoch 40/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 0.2884\n",
      "Epoch 41/100\n",
      "1622/1622 [==============================] - 1s 753us/sample - loss: 0.2658\n",
      "Epoch 42/100\n",
      "1622/1622 [==============================] - 1s 746us/sample - loss: 0.2788\n",
      "Epoch 43/100\n",
      "1622/1622 [==============================] - 1s 780us/sample - loss: 0.2650\n",
      "Epoch 44/100\n",
      "1622/1622 [==============================] - 1s 755us/sample - loss: 0.2944\n",
      "Epoch 45/100\n",
      "1622/1622 [==============================] - 1s 745us/sample - loss: 0.2674\n",
      "Epoch 46/100\n",
      "1622/1622 [==============================] - 1s 744us/sample - loss: 0.2908\n",
      "Epoch 47/100\n",
      "1622/1622 [==============================] - 1s 758us/sample - loss: 0.2840\n",
      "Epoch 48/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.2948\n",
      "Epoch 49/100\n",
      "1622/1622 [==============================] - 1s 764us/sample - loss: 0.2551\n",
      "Epoch 50/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.2705\n",
      "Epoch 51/100\n",
      "1622/1622 [==============================] - 1s 747us/sample - loss: 0.2702\n",
      "Epoch 52/100\n",
      "1622/1622 [==============================] - 1s 747us/sample - loss: 0.2896\n",
      "Epoch 53/100\n",
      "1622/1622 [==============================] - 1s 752us/sample - loss: 0.2714\n",
      "Epoch 54/100\n",
      "1622/1622 [==============================] - 1s 769us/sample - loss: 0.2802\n",
      "Epoch 55/100\n",
      "1622/1622 [==============================] - 1s 815us/sample - loss: 0.2722\n",
      "Epoch 56/100\n",
      "1622/1622 [==============================] - 1s 812us/sample - loss: 0.2594\n",
      "Epoch 57/100\n",
      "1622/1622 [==============================] - 1s 749us/sample - loss: 0.2554\n",
      "Epoch 58/100\n",
      "1622/1622 [==============================] - 1s 742us/sample - loss: 0.2665\n",
      "Epoch 59/100\n",
      "1622/1622 [==============================] - 1s 775us/sample - loss: 0.2650\n",
      "Epoch 60/100\n",
      "1622/1622 [==============================] - 1s 767us/sample - loss: 0.2669\n",
      "Epoch 61/100\n",
      "1622/1622 [==============================] - 1s 790us/sample - loss: 0.2969\n",
      "Epoch 62/100\n",
      "1622/1622 [==============================] - 1s 727us/sample - loss: 0.2551\n",
      "Epoch 63/100\n",
      "1622/1622 [==============================] - 1s 759us/sample - loss: 0.2692\n",
      "Epoch 64/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.2673\n",
      "Epoch 65/100\n",
      "1622/1622 [==============================] - 1s 774us/sample - loss: 0.2821\n",
      "Epoch 66/100\n",
      "1622/1622 [==============================] - 1s 766us/sample - loss: 0.2727\n",
      "Epoch 67/100\n",
      "1622/1622 [==============================] - 1s 815us/sample - loss: 0.2628\n",
      "Epoch 68/100\n",
      "1622/1622 [==============================] - 1s 725us/sample - loss: 0.2719\n",
      "Epoch 69/100\n",
      "1622/1622 [==============================] - 1s 732us/sample - loss: 0.2828\n",
      "Epoch 70/100\n",
      "1622/1622 [==============================] - 1s 753us/sample - loss: 0.2794\n",
      "Epoch 71/100\n",
      "1622/1622 [==============================] - 1s 754us/sample - loss: 0.2873\n",
      "Epoch 72/100\n",
      "1622/1622 [==============================] - 1s 805us/sample - loss: 0.2819\n",
      "Epoch 73/100\n",
      "1622/1622 [==============================] - 1s 757us/sample - loss: 0.2585\n",
      "Epoch 74/100\n",
      "1622/1622 [==============================] - 1s 728us/sample - loss: 0.2553\n",
      "Epoch 75/100\n",
      "1622/1622 [==============================] - 1s 729us/sample - loss: 0.2676\n",
      "Epoch 76/100\n",
      "1622/1622 [==============================] - 1s 762us/sample - loss: 0.2667\n",
      "Epoch 77/100\n",
      "1622/1622 [==============================] - 1s 825us/sample - loss: 0.2588\n",
      "Epoch 78/100\n",
      "1622/1622 [==============================] - 1s 806us/sample - loss: 0.2475\n",
      "Epoch 79/100\n",
      "1622/1622 [==============================] - 1s 750us/sample - loss: 0.2514\n",
      "Epoch 80/100\n",
      "1622/1622 [==============================] - 1s 764us/sample - loss: 0.2610\n",
      "Epoch 81/100\n",
      "1622/1622 [==============================] - 1s 789us/sample - loss: 0.2738\n",
      "Epoch 82/100\n",
      "1622/1622 [==============================] - 1s 803us/sample - loss: 0.2687\n",
      "Epoch 83/100\n",
      "1622/1622 [==============================] - 1s 769us/sample - loss: 0.2478\n",
      "Epoch 84/100\n",
      "1622/1622 [==============================] - 1s 741us/sample - loss: 0.2521\n",
      "Epoch 85/100\n",
      "1622/1622 [==============================] - 1s 766us/sample - loss: 0.2688\n",
      "Epoch 86/100\n",
      "1622/1622 [==============================] - 1s 751us/sample - loss: 0.2767\n",
      "Epoch 87/100\n",
      "1622/1622 [==============================] - 1s 786us/sample - loss: 0.2768\n",
      "Epoch 88/100\n",
      "1622/1622 [==============================] - 1s 813us/sample - loss: 0.2869\n",
      "Epoch 89/100\n",
      "1622/1622 [==============================] - 1s 762us/sample - loss: 0.2627\n",
      "Epoch 90/100\n",
      "1622/1622 [==============================] - 1s 743us/sample - loss: 0.2697\n",
      "Epoch 91/100\n",
      "1622/1622 [==============================] - 1s 754us/sample - loss: 0.2748\n",
      "Epoch 92/100\n",
      "1622/1622 [==============================] - 1s 733us/sample - loss: 0.2584\n",
      "Epoch 93/100\n",
      "1622/1622 [==============================] - 1s 774us/sample - loss: 0.2717\n",
      "Epoch 94/100\n",
      "1622/1622 [==============================] - 1s 767us/sample - loss: 0.2690\n",
      "Epoch 95/100\n",
      "1622/1622 [==============================] - 1s 808us/sample - loss: 0.2867\n",
      "Epoch 96/100\n",
      "1622/1622 [==============================] - 1s 755us/sample - loss: 0.2764\n",
      "Epoch 97/100\n",
      "1622/1622 [==============================] - 1s 739us/sample - loss: 0.2761\n",
      "Epoch 98/100\n",
      "1622/1622 [==============================] - 1s 773us/sample - loss: 0.2763\n",
      "Epoch 99/100\n",
      "1622/1622 [==============================] - 1s 814us/sample - loss: 0.2671\n",
      "Epoch 100/100\n",
      "1622/1622 [==============================] - 1s 798us/sample - loss: 0.2630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8fcf6ebe50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt=keras.optimizers.RMSprop(learning_rate=0.00001)\n",
    "cnnlstm.model.compile(optimizer=opt,    # 这里是优化器的选择\n",
    "                          loss='mean_absolute_error'  # 损失函数的选择\n",
    "                                )                              # 训练\n",
    "# cnnlstm.model.summary()\n",
    "cnnlstm.model.fit(datas, labels, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 146 data names\n",
      "datas shape:  (146, 1000, 1)\n",
      "labels shape:  (146, 1)\n",
      "146/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 10ms/sample - loss: 7.4877\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# evalation\n",
    "####################\n",
    "test_datas,test_labels=trainset('/home/wcj/ReferenceProject/PPGnet/12thData')     \n",
    "prediction=cnnlstm.model.evaluate(test_datas,test_labels,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1328 data names\n",
      "datas shape:  (1328, 1000, 1)\n",
      "labels shape:  (1328, 1)\n",
      "1328/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 556us/sample - loss: 26.6338\n"
     ]
    }
   ],
   "source": [
    "test_datas_10,test_labels_10=trainset('/home/wcj/ReferenceProject/PPGnet/testdata')     \n",
    "prediction=cnnlstm.model.evaluate(test_datas_10,test_labels_10,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# save model\n",
    "######################\n",
    "cnnlstm.model.save('epoch_300-batch_size-100.h5')\n",
    "# cnnlstm.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           multiple                  1312      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           multiple                  40992     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc multiple                  128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               multiple                  4132000   \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               multiple                  8004000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  1001      \n",
      "=================================================================\n",
      "Total params: 12,179,561\n",
      "Trainable params: 12,179,433\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# load model\n",
    "###################\n",
    "\n",
    "#重新创建完全相同的模型，包括其权重和优化程序\n",
    "new_model = keras.models.load_model('epoch_300-batch_size-100.h5')\n",
    "\n",
    "# 显示网络结构\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from scipy.io import loadmat\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(1, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([1,2,3,4,5])\n",
    "a=np.expand_dims(a,axis=0)\n",
    "print(a.shape)\n",
    "b=np.array([[6,7,8,9,10]])\n",
    "print(b.shape)\n",
    "c=np.concatenate((a,b),axis=0)\n",
    "d=np.array([[11,12,13,14,15]])\n",
    "e=np.concatenate((c,d),axis=0)\n",
    "e.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (1000,), types: tf.float64>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath=\"/home/wcj/ReferenceProject/PPGnet/ppghr/1-104-150.9534.mat\"\n",
    "time=loadmat(filepath)\n",
    "time=time['ppg']\n",
    "ds1 = tf.data.Dataset.from_tensor_slices(time)\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'/home/wcj/ReferenceProject/PPGnet/ppghr/11-78-168.4492.mat', shape=(), dtype=string)\n",
      "tf.Tensor(b'/home/wcj/ReferenceProject/PPGnet/ppghr/9-140-150.1581.mat', shape=(), dtype=string)\n",
      "tf.Tensor(b'/home/wcj/ReferenceProject/PPGnet/ppghr/1-93-151.919.mat', shape=(), dtype=string)\n",
      "tf.Tensor(b'/home/wcj/ReferenceProject/PPGnet/ppghr/6-111-138.587.mat', shape=(), dtype=string)\n",
      "tf.Tensor(b'/home/wcj/ReferenceProject/PPGnet/ppghr/4-129-164.0625.mat', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ds6 = tf.data.Dataset.list_files(\"/home/wcj/ReferenceProject/PPGnet/ppghr/*.mat\")\n",
    "for file in ds6.take(5):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: 'DType' object is not callable\nTraceback (most recent call last):\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 52, in eager_py_func\n    token, \"Tout\", Tout)\n\ntensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 219, in __call__\n    return func(device, token, args)\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 113, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-30-a3191ecfbcee>\", line 3, in LoadData\n    filepath=tf.string(filepath).values\n\nTypeError: 'DType' object is not callable\n\n [Op:EagerPyFunc]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-847782203125>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     print(label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoadData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/home/wcj/ReferenceProject/PPGnet/ppghr/1-104-150.9534.mat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(func, inp, Tout, name)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m   \"\"\"\n\u001b[0;32m--> 407\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_internal_py_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[0;34m(func, inp, Tout, stateful, eager, is_grad_func, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     result = gen_script_ops.eager_py_func(\n\u001b[0;32m--> 296\u001b[0;31m         input=inp, token=token, Tout=Tout, name=name)\n\u001b[0m\u001b[1;32m    297\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(input, token, Tout, name)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         return eager_py_func_eager_fallback(\n\u001b[0;32m---> 57\u001b[0;31m             input, token=token, Tout=Tout, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m     58\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func_eager_fallback\u001b[0;34m(input, token, Tout, name, ctx)\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m   _result = _execute.execute(b\"EagerPyFunc\", len(Tout), inputs=_inputs_flat,\n\u001b[0;32m--> 107\u001b[0;31m                              attrs=_attrs, ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m    108\u001b[0m   _execute.record_gradient(\n\u001b[1;32m    109\u001b[0m       \"EagerPyFunc\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TypeError: 'DType' object is not callable\nTraceback (most recent call last):\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 52, in eager_py_func\n    token, \"Tout\", Tout)\n\ntensorflow.python.eager.core._FallbackException: This function does not handle the case of the path where all inputs are not already EagerTensors.\n\n\nDuring handling of the above exception, another exception occurred:\n\n\nTraceback (most recent call last):\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 219, in __call__\n    return func(device, token, args)\n\n  File \"/home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 113, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-30-a3191ecfbcee>\", line 3, in LoadData\n    filepath=tf.string(filepath).values\n\nTypeError: 'DType' object is not callable\n\n [Op:EagerPyFunc]"
     ]
    }
   ],
   "source": [
    "# for i,(data,label) in enumerate(ds6.map(tf.py_function(LoadData)).ake(2)):\n",
    "#     print(data.shape)\n",
    "#     print(label)\n",
    "    \n",
    "tf.py_function(LoadData,[\"/home/wcj/ReferenceProject/PPGnet/ppghr/1-104-150.9534.mat\"],[tf.uint16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/tmp/tmp9x2comq1.py\u001b[0m(26)\u001b[0;36mtf__read_mat\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     25 \u001b[0;31m        \u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0mdata0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> output[0]\n",
      "<tf.Tensor 'EagerPyFunc:0' shape=<unknown> dtype=float32>\n",
      "ipdb> output[0].shape\n",
      "TensorShape(None)\n",
      "ipdb> n\n",
      "> \u001b[0;32m/tmp/tmp9x2comq1.py\u001b[0m(27)\u001b[0;36mtf__read_mat\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        \u001b[0mdata0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "TypeError: Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64\n",
      "> \u001b[0;32m/tmp/tmp9x2comq1.py\u001b[0m(27)\u001b[0;36mtf__read_mat\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m        \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 27 \u001b[0;31m        \u001b[0mdata0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0mdata1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_mat_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-4-c7f884d25974>:19 read_mat  *\n        data0 = tf.reshape(output[0], shape)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8117 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:631 _apply_op_helper\n        param_name=input_name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:60 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c7f884d25974>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/wcj/ReferenceProject/PPGnet/ppghr/*.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1902\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1903\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1904\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use `tf.data.Dataset.map()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3455\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3456\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1852\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1854\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2688\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-4-c7f884d25974>:19 read_mat  *\n        data0 = tf.reshape(output[0], shape)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:131 reshape\n        result = gen_array_ops.reshape(tensor, shape, name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:8117 reshape\n        \"Reshape\", tensor=tensor, shape=shape, name=name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:631 _apply_op_helper\n        param_name=input_name)\n    /home/wcj/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:60 _SatisfiesTypeConstraint\n        \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\n    TypeError: Value passed to parameter 'shape' has DataType float32 not in list of allowed values: int32, int64\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# https://stackoverflow.com/questions/46890387/how-to-read-mat-file-format-in-tensorflow?rq=1 \n",
    "##########################\n",
    "def read_mat(filepath):   \n",
    "    def _read_mat(filepath):\n",
    "        matfile = loadmat(filepath)\n",
    "        data0 = matfile['ppg']\n",
    "#         data1 = matfile['data1']\n",
    "#         data2 = mat_contents['data2']\n",
    "#         shape0 = matfile['data0'].shape\n",
    "        listslice=filepath.split('-')\n",
    "        label=listslice[2][:-4]\n",
    "        return data0,label\n",
    "#         return data0, data1, data2, np.asarray(shape0)\n",
    "\n",
    "    output = tf.py_function(_read_mat, [filepath], [tf.float32])\n",
    "    ipdb.set_trace()\n",
    "    shape = output[0]\n",
    "    data0 = tf.reshape(output[0], shape)\n",
    "    data1 = tf.reshape(output[1], shape)\n",
    "    data2 = tf.reshape(output[2], shape)\n",
    "    return data0, data1, data2\n",
    "\n",
    "dataset = tf.data.Dataset.list_files('/home/wcj/ReferenceProject/PPGnet/ppghr/*.mat')\n",
    "dataset = dataset.map(read_mat, num_parallel_calls=16)\n",
    "dataset = dataset.repeat(100)\n",
    "dataset = dataset.batch(8)\n",
    "dataset = dataset.prefetch(8)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "sess = tf.Session()\n",
    "sess.run(iterator.initializer)\n",
    "values = sess.run(iterator.get_next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-30-a3191ecfbcee>:3 LoadData  *\n        filepath=tf.string(filepath).values\n\n    TypeError: 'DType' object is not callable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-32517f8d0aca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mds_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/wcj/ReferenceProject/PPGnet/ppghr/*.mat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m            \u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLoadData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1902\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1903\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1904\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1906\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use `tf.data.Dataset.map()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3453\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3454\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3455\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3456\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2693\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1852\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1854\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2687\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2688\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2689\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2634\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2635\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/pytorch/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-30-a3191ecfbcee>:3 LoadData  *\n        filepath=tf.string(filepath).values\n\n    TypeError: 'DType' object is not callable\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=100\n",
    "ds_train = tf.data.Dataset.list_files(\"/home/wcj/ReferenceProject/PPGnet/ppghr/*.mat\") \\\n",
    "           .map(LoadData, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "           .shuffle(buffer_size = 1000).batch(BATCH_SIZE) \\\n",
    "           .prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
